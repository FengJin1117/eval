import warnings 
warnings.filterwarnings("ignore")

import os
import json
import pandas as pd
import argparse
import subprocess
import time
import glob
from multiprocessing import Pool

def preprocess_pred_dir(pred_dir):
    """é¢„å¤„ç† pred_dirï¼šå»æ‰ wav æ–‡ä»¶åå‰ç¼€ opencpop_ å’Œ acesinger_13#"""
    prefix_list = ["opencpop_", "acesinger_13#"]

    for wav_path in glob.glob(os.path.join(pred_dir, "*.wav")):
        fname = os.path.basename(wav_path)
        new_name = fname
        for prefix in prefix_list:
            if new_name.startswith(prefix):
                new_name = new_name[len(prefix):]
        if new_name != fname:
            new_path = os.path.join(pred_dir, new_name)
            # å¦‚æœæ–°æ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
            if os.path.exists(new_path):
                os.remove(new_path)
            os.rename(wav_path, new_path)
            # print(f"é‡å‘½å: {fname} -> {new_name}")

def run_scorer(args):
    pred_scp, output_file, part_id = args
    cmd = [
        "python", "../versa/versa/bin/scorer.py",
        "--score_config", "../versa/egs/separate_metrics/sheet_ssqa.yaml",
        "--pred", pred_scp,
        "--output_file", output_file,
        "--io", "soundfile"
    ]
    print(f"[Part {part_id}] Running command: {' '.join(cmd)}\n")

    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    for line in process.stdout:
        print(f"[Part {part_id}] {line}", end='')
    process.wait()
    return part_id

def split_file(input_file, num_parts, output_dir, prefix):
    """æŠŠ input_file æ‹†æˆ num_parts ä¸ªå°æ–‡ä»¶"""
    with open(input_file, "r") as f:
        lines = f.readlines()
    total = len(lines)
    part_size = (total + num_parts - 1) // num_parts

    files = []
    for i in range(num_parts):
        part_lines = lines[i * part_size : (i + 1) * part_size]
        if not part_lines:
            break
        part_file = os.path.join(output_dir, f"{prefix}_{i+1}.scp")
        with open(part_file, "w") as f:
            f.writelines(part_lines)
        files.append(part_file)
    return files

def eval(pred_dir, output_dir, num_jobs=1):
    start_time = time.time()
    os.makedirs(output_dir, exist_ok=True)

    # å‡†å¤‡ pred.scp
    pred_scp = os.path.join(output_dir, "pred.scp")
    with open(pred_scp, "w") as f:
        for wav_path in sorted(glob.glob(os.path.join(pred_dir, "*.wav"))):
            utt_id = os.path.splitext(os.path.basename(wav_path))[0]
            abs_path = os.path.abspath(wav_path)
            f.write(f"{utt_id} {abs_path}\n")

    # æ‹†åˆ† pred.scp
    pred_parts = split_file(pred_scp, num_jobs, output_dir, "pred_part")

    # æ¯ä¸ªå­è¿›ç¨‹ä»»åŠ¡å‚æ•°
    tasks = []
    for i, part_file in enumerate(pred_parts, start=1):
        output_file = os.path.join(output_dir, f"result_part_{i}.jsonl")
        tasks.append((part_file, output_file, i))

    # å¤šè¿›ç¨‹è·‘
    with Pool(processes=num_jobs) as pool:
        for i, part_id in enumerate(pool.imap_unordered(run_scorer, tasks), start=1):
            print(f"âœ… Progress: {i}/{len(tasks)} parts finished (last done: Part {part_id})")

    print(f"\nğŸ‰ All done in {time.time() - start_time:.2f} seconds.")

def get_average_score(root_dir): 
    records = []

    # éå†æ‰€æœ‰ .jsonl æ–‡ä»¶
    for filename in os.listdir(root_dir):
        if filename.endswith('.jsonl'):
            filepath = os.path.join(root_dir, filename)
            with open(filepath, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        data = json.loads(line)
                        file_id = data['key'].replace('.wav', '')
                        if "sheet_ssqa" in data:
                            records.append({
                                'æ–‡ä»¶ID': file_id,
                                'sheet_ssqa': data['sheet_ssqa']
                            })
                    except json.JSONDecodeError:
                        print(f"âš ï¸ è·³è¿‡æ— æ•ˆè¡Œï¼š{line}")

    df = pd.DataFrame(records)
    if not df.empty:
        print(f"âœ… æˆåŠŸæ•°: {len(df)}")
        print(f"ğŸ“Š sheet_ssqa å¹³å‡å€¼ï¼š{df['sheet_ssqa'].mean():.2f}")
    else:
        print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„è¯„åˆ†è®°å½•ã€‚")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--pred_dir", type=str, required=True, help="é¢„æµ‹éŸ³é¢‘æ‰€åœ¨è·¯å¾„")
    parser.add_argument("--no_eval", action='store_true', help="ä¸è¯„ä¼°ï¼Œåªè®¡ç®—å¹³å‡åˆ†")
    args = parser.parse_args()

    pred_dir = args.pred_dir
    output_dir = os.path.join(pred_dir, "eval_ssqa")
    os.makedirs(output_dir, exist_ok=True)

    # é¢„å¤„ç† pred_dir
    preprocess_pred_dir(pred_dir)

    if not args.no_eval:
        eval(pred_dir, output_dir, num_jobs=1)
        
    get_average_score(output_dir)
